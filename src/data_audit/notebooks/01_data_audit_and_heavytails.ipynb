{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "19e44c01",
      "metadata": {},
      "source": [
        "# Data Audit & Heavy-Tails Notebook\n",
        "*Generated: 2025-01-09*\n",
        "\n",
        "This notebook performs:\n",
        "1) Schema checks & parsing of list-like fields  \n",
        "2) Heavy-tail diagnostics using **Clauset–Shalizi–Newman (2009)** discrete power-law workflow  \n",
        "3) Overdispersion tests (Poisson) per **Dean–Lawless (1989)** and **Cameron–Trivedi (1990)**  \n",
        "4) Edge case analysis and guardrails\n",
        "\n",
        "> References: Clauset et al. (2009, SIAM Review), Alstott et al. (2014, *powerlaw* package), Dean & Lawless (1989), Cameron & Trivedi (1990).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "60d7180a",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mast\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "# %% [code] Imports & Config\n",
        "import os, json, math, logging, pathlib, re, ast, time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Paths (edit as needed)\n",
        "DATA_CSV = os.environ.get(\"GOODREADS_CSV\", \"../../data/processed/romance_books_main_final.csv\")\n",
        "ARTIFACTS_DIR = pathlib.Path(\"./audit_artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "log = logging.getLogger(\"audit\")\n",
        "log.info(f\"Notebook start. CSV: {DATA_CSV}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c2ad3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Load data & schema checks\n",
        "df = pd.read_csv(DATA_CSV)\n",
        "log.info(f\"Loaded dataframe with shape {df.shape}\")\n",
        "\n",
        "expected_cols = [\n",
        " 'work_id','book_id_list_en','title','publication_year','num_pages_median','description','language_codes_en',\n",
        " 'author_id','author_name','author_average_rating','author_ratings_count','series_id','series_title',\n",
        " 'ratings_count_sum','text_reviews_count_sum','average_rating_weighted_mean','genres_str','shelves_str','series_works_count_numeric'\n",
        "]\n",
        "\n",
        "missing = [c for c in expected_cols if c not in df.columns]\n",
        "extra = [c for c in df.columns if c not in expected_cols]\n",
        "schema_ok = len(missing)==0\n",
        "\n",
        "schema_report = {\n",
        "    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "    \"n_rows\": int(len(df)),\n",
        "    \"n_cols\": int(df.shape[1]),\n",
        "    \"present_cols\": list(df.columns),\n",
        "    \"expected_cols\": expected_cols,\n",
        "    \"missing_cols\": missing,\n",
        "    \"extra_cols\": extra,\n",
        "    \"schema_ok\": schema_ok\n",
        "}\n",
        "with open(ARTIFACTS_DIR / \"schema_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(schema_report, f, indent=2)\n",
        "log.info(f\"Schema report written. OK? {schema_ok}\")\n",
        "\n",
        "# Quick dtype summary\n",
        "dtype_summary = df.dtypes.astype(str).to_dict()\n",
        "pd.Series(dtype_summary).to_csv(ARTIFACTS_DIR / \"dtype_summary.csv\")\n",
        "dtype_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9974b88b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Parse list-like fields & simple unit checks\n",
        "\n",
        "def parse_listlike(s):\n",
        "    \"\"\"Robust parser for list-like strings.\n",
        "    Tries literal_eval (e.g., \"['123','456']\"), falls back to comma split.\n",
        "    Returns list[str].\n",
        "    \"\"\"\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    s = str(s).strip()\n",
        "    if not s:\n",
        "        return []\n",
        "    # Try literal list\n",
        "    try:\n",
        "        v = ast.literal_eval(s)\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            return [str(x).strip() for x in v]\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback: comma-separated\n",
        "    return [x.strip() for x in s.split(\",\") if x.strip()]\n",
        "\n",
        "for col in [\"book_id_list_en\",\"genres_str\",\"shelves_str\"]:\n",
        "    if col in df.columns:\n",
        "        df[col + \"_list\"] = df[col].apply(parse_listlike)\n",
        "\n",
        "# Minimal unit checks\n",
        "assert df[\"book_id_list_en_list\"].apply(lambda x: isinstance(x, list)).all(), \"book_id_list_en_list parse failed\"\n",
        "assert df[\"genres_str_list\"].apply(lambda x: isinstance(x, list)).all(), \"genres_str_list parse failed\"\n",
        "assert df[\"shelves_str_list\"].apply(lambda x: isinstance(x, list)).all(), \"shelves_str_list parse failed\"\n",
        "\n",
        "# Counts non-negative\n",
        "for c in [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]:\n",
        "    if c in df.columns:\n",
        "        assert (df[c] >= 0).all(), f\"Negative counts found in {c}\"\n",
        "\n",
        "# Save small preview\n",
        "df.head(50).to_csv(ARTIFACTS_DIR / \"parsed_preview.csv\", index=False)\n",
        "log.info(\"Parsing complete and basic unit checks passed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32d5dc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Heavy-tail visuals: CCDF and log-binned histograms\n",
        "from math import ceil\n",
        "\n",
        "def plot_ccdf(x, title, fname):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    x = x[x >= 0]\n",
        "    x_sorted = np.sort(x)\n",
        "    n = len(x_sorted)\n",
        "    if n == 0:\n",
        "        log.warning(f\"No data for {title}\")\n",
        "        return\n",
        "    y = 1.0 - np.arange(1, n+1)/n\n",
        "    plt.figure()\n",
        "    plt.loglog(x_sorted, y, marker='.', linestyle='none')\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"CCDF P(X>=x)\")\n",
        "    plt.title(title + \" — Empirical CCDF (log–log)\")\n",
        "    plt.grid(True, which=\"both\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTIFACTS_DIR / fname, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "def plot_log_binned_hist(x, title, fname, bins=50):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    x = x[x > 0]\n",
        "    if len(x) == 0:\n",
        "        log.warning(f\"No positive data for {title}\")\n",
        "        return\n",
        "    # Log-spaced bins for visualization ONLY (do not fit on binned data)\n",
        "    xmin, xmax = x.min(), x.max()\n",
        "    edges = np.logspace(np.log10(xmin), np.log10(xmax), bins)\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=edges, density=True)\n",
        "    plt.xscale(\"log\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.xlabel(\"x (log)\")\n",
        "    plt.ylabel(\"Density (log)\")\n",
        "    plt.title(title + \" — Log-binned histogram (for visualization only)\")\n",
        "    plt.grid(True, which=\"both\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTIFACTS_DIR / (\"hist_\" + fname), dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "targets = [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]\n",
        "for var in targets:\n",
        "    if var in df.columns:\n",
        "        x = df[var].values\n",
        "        plot_ccdf(x, f\"{var}\", f\"ccdf_{var}.png\")\n",
        "        plot_log_binned_hist(x, f\"{var}\", f\"{var}.png\")\n",
        "log.info(\"Heavy-tail visualizations saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e4016b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] CSN (2009) discrete power-law fits & model comparison (via `powerlaw`)\n",
        "# This cell uses the `powerlaw` package (Alstott et al., 2014).\n",
        "# If not installed, install in your environment: `pip install powerlaw`\n",
        "\n",
        "try:\n",
        "    import powerlaw\n",
        "    HAVE_POWERLAW = True\n",
        "except Exception as e:\n",
        "    HAVE_POWERLAW = False\n",
        "    log.warning(\"`powerlaw` not available. Install with `pip install powerlaw` to enable CSN fits.\")\n",
        "\n",
        "def csn_fit_report(x_raw, varname):\n",
        "    if not HAVE_POWERLAW:\n",
        "        return None\n",
        "    x = np.asarray(x_raw, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    # CSN tail model for counts: use strictly positive support\n",
        "    x = x[x >= 1]\n",
        "    if len(x) < 50:\n",
        "        log.warning(f\"{varname}: too few positive observations for tail fitting ({len(x)}).\")\n",
        "        return None\n",
        "    fit = powerlaw.Fit(x, discrete=True, estimate_discrete=True, verbose=False)\n",
        "    pl = fit.power_law\n",
        "    # Likelihood ratio tests vs alternatives\n",
        "    comps = {}\n",
        "    for alt in [\"lognormal\",\"exponential\",\"truncated_power_law\",\"stretched_exponential\"]:\n",
        "        try:\n",
        "            R, p = fit.distribution_compare('power_law', alt)\n",
        "            comps[alt] = {\"LR\": float(R), \"p\": float(p)}\n",
        "        except Exception as e:\n",
        "            comps[alt] = {\"LR\": None, \"p\": None}\n",
        "    report = {\n",
        "        \"var\": varname,\n",
        "        \"n_positive\": int(len(x)),\n",
        "        \"xmin\": float(pl.xmin),\n",
        "        \"alpha\": float(pl.alpha),\n",
        "        \"D_KS\": float(fit.D),\n",
        "        # Note: `powerlaw`'s gof p-value estimation can be computationally heavy; \n",
        "        # here we use the default KS; for full GOF bootstrap, see docs.\n",
        "        \"tail_fraction\": float((x >= pl.xmin).mean()),\n",
        "        \"comparisons\": comps,\n",
        "    }\n",
        "    return report\n",
        "\n",
        "csn_reports = []\n",
        "for var in [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]:\n",
        "    if var in df.columns:\n",
        "        rep = csn_fit_report(df[var].values, var)\n",
        "        if rep:\n",
        "            csn_reports.append(rep)\n",
        "\n",
        "if csn_reports:\n",
        "    with open(ARTIFACTS_DIR / \"csn_powerlaw_reports.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(csn_reports, f, indent=2)\n",
        "    log.info(\"CSN reports saved to csn_powerlaw_reports.json\")\n",
        "else:\n",
        "    log.info(\"CSN reports not generated (missing powerlaw or insufficient data).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e4c32e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Overdispersion tests: Dean–Lawless (Pearson chi-square) & Cameron–Trivedi (auxiliary OLS)\n",
        "# Requires statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def fit_poisson(y, X):\n",
        "    X_ = sm.add_constant(X, has_constant='add')\n",
        "    model = sm.GLM(y, X_, family=sm.families.Poisson())\n",
        "    res = model.fit()\n",
        "    return res\n",
        "\n",
        "def dean_lawless_test(res):\n",
        "    # Pearson chi-square should have E ≈ df and Var ≈ 2*df under Poisson\n",
        "    chi2 = res.pearson_chi2\n",
        "    df = res.df_resid\n",
        "    z = (chi2 - df) / math.sqrt(2.0*df) if df > 0 else np.nan\n",
        "    # two-sided p-value from N(0,1)\n",
        "    from math import erf, sqrt\n",
        "    p = 2*(1 - 0.5*(1 + erf(abs(z)/sqrt(2))))\n",
        "    return {\"pearson_chi2\": chi2, \"df\": df, \"z\": z, \"p_two_sided\": p}\n",
        "\n",
        "def cameron_trivedi_test(y, mu):\n",
        "    # Following auxiliary regression: Y* = ((y - mu)^2 - y) / mu  onto mu (no intercept)\n",
        "    # Reference: Cameron & Trivedi (1990); see also CRAN overdisp vignette\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    mu = np.asarray(mu, dtype=float)\n",
        "    mask = np.isfinite(y) & np.isfinite(mu) & (mu > 0)\n",
        "    y = y[mask]; mu = mu[mask]\n",
        "    y_star = ((y - mu)**2 - y) / mu\n",
        "    X_aux = mu.reshape(-1,1)  # no intercept\n",
        "    aux_res = sm.OLS(y_star, X_aux).fit()\n",
        "    alpha_hat = aux_res.params[0]\n",
        "    t_stat = aux_res.tvalues[0]\n",
        "    p_val = aux_res.pvalues[0]\n",
        "    return {\"alpha_hat\": alpha_hat, \"t\": t_stat, \"p\": p_val, \"n\": int(mask.sum())}\n",
        "\n",
        "# Example design matrix: simple intercept-only model for baseline\n",
        "targets = [\"ratings_count_sum\",\"text_reviews_count_sum\"]\n",
        "X_baseline = pd.DataFrame({\"intercept_only\": np.ones(len(df))})\n",
        "\n",
        "overdisp_results = []\n",
        "for var in targets:\n",
        "    if var in df.columns:\n",
        "        y = df[var].values\n",
        "        res = fit_poisson(y, X_baseline)\n",
        "        dl = dean_lawless_test(res)\n",
        "        ct = cameron_trivedi_test(y, res.fittedvalues)\n",
        "        overdisp_results.append({\"var\": var, \"dean_lawless\": dl, \"cameron_trivedi\": ct})\n",
        "\n",
        "with open(ARTIFACTS_DIR / \"overdispersion_tests.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(overdisp_results, f, indent=2)\n",
        "log.info(\"Overdispersion tests saved to overdispersion_tests.json\")\n",
        "overdisp_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a199ff5",
      "metadata": {},
      "source": [
        "## Outputs generated\n",
        "- `audit_artifacts/schema_report.json` — column presence & dtype summary\n",
        "- `audit_artifacts/dtype_summary.csv` — dtypes\n",
        "- `audit_artifacts/parsed_preview.csv` — first 50 rows after parsing\n",
        "- `audit_artifacts/ccdf_*.png`, `audit_artifacts/hist_*.png` — heavy-tail visuals\n",
        "- `audit_artifacts/csn_powerlaw_reports.json` — (if `powerlaw` installed) CSN fits\n",
        "- `audit_artifacts/overdispersion_tests.json` — Dean–Lawless & Cameron–Trivedi test results\n",
        "\n",
        "> Note: **Do not** fit lines to binned histograms. Use CSN MLE + KS (and LR comparisons) for tail inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542419b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Edge case analysis and summary\n",
        "\n",
        "# Analyze zeros and support issues\n",
        "edge_case_report = {\n",
        "    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "    \"zero_analysis\": {},\n",
        "    \"support_analysis\": {},\n",
        "    \"recommendations\": []\n",
        "}\n",
        "\n",
        "for var in [\"ratings_count_sum\", \"text_reviews_count_sum\", \"author_ratings_count\"]:\n",
        "    if var in df.columns:\n",
        "        x = df[var].values\n",
        "        zeros = (x == 0).sum()\n",
        "        total = len(x)\n",
        "        \n",
        "        edge_case_report[\"zero_analysis\"][var] = {\n",
        "            \"zero_count\": int(zeros),\n",
        "            \"zero_fraction\": float(zeros / total),\n",
        "            \"total_observations\": int(total)\n",
        "        }\n",
        "        \n",
        "        # Check for potential zero-inflation\n",
        "        if zeros / total > 0.1:  # More than 10% zeros\n",
        "            edge_case_report[\"recommendations\"].append(\n",
        "                f\"{var}: High zero fraction ({zeros/total:.1%}) - consider zero-inflated models\"\n",
        "            )\n",
        "\n",
        "# Summary statistics\n",
        "summary_stats = {\n",
        "    \"dataset_shape\": df.shape,\n",
        "    \"missing_values\": df.isnull().sum().to_dict(),\n",
        "    \"edge_case_report\": edge_case_report\n",
        "}\n",
        "\n",
        "with open(ARTIFACTS_DIR / \"edge_case_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(summary_stats, f, indent=2)\n",
        "\n",
        "log.info(\"Edge case analysis complete.\")\n",
        "print(\"\\n=== AUDIT SUMMARY ===\")\n",
        "print(f\"Dataset: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
        "print(f\"Schema OK: {schema_ok}\")\n",
        "print(f\"Artifacts saved to: {ARTIFACTS_DIR}\")\n",
        "if edge_case_report[\"recommendations\"]:\n",
        "    print(\"\\nRecommendations:\")\n",
        "    for rec in edge_case_report[\"recommendations\"]:\n",
        "        print(f\"  - {rec}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Audit & Heavy-Tails Notebook\n",
        "*Generated: 2025-09-25 22:16:03*\n",
        "\n",
        "This notebook performs:\n",
        "1) Schema checks & parsing of list-like fields  \n",
        "2) Heavy-tail diagnostics using **Clauset–Shalizi–Newman (2009)** discrete power-law workflow  \n",
        "3) Overdispersion tests (Poisson) per **Dean–Lawless (1989)** and **Cameron–Trivedi (1990)**  \n",
        "4) Leakage filters for non-content shelves\n",
        "\n",
        "> References: Clauset et al. (2009, SIAM Review), Alstott et al. (2014, *powerlaw* package), Dean & Lawless (1989), Cameron & Trivedi (1990).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Imports & Config\n",
        "import os, json, math, logging, pathlib, re, ast, time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Paths (edit as needed)\n",
        "DATA_CSV = os.environ.get(\"GOODREADS_CSV\", \"../../data/processed/romance_books_main_final.csv\")\n",
        "ARTIFACTS_DIR = pathlib.Path(\"./audit_artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "log = logging.getLogger(\"audit\")\n",
        "log.info(f\"Notebook start. CSV: {DATA_CSV}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Load data & schema checks\n",
        "df = pd.read_csv(DATA_CSV)\n",
        "log.info(f\"Loaded dataframe with shape {df.shape}\")\n",
        "\n",
        "expected_cols = [\n",
        " 'work_id','book_id_list_en','title','publication_year','num_pages_median','description','language_codes_en',\n",
        " 'author_id','author_name','author_average_rating','author_ratings_count','series_id','series_title',\n",
        " 'ratings_count_sum','text_reviews_count_sum','average_rating_weighted_mean','genres_str','shelves_str','series_works_count_numeric'\n",
        "]\n",
        "\n",
        "missing = [c for c in expected_cols if c not in df.columns]\n",
        "extra = [c for c in df.columns if c not in expected_cols]\n",
        "schema_ok = len(missing)==0\n",
        "\n",
        "schema_report = {\n",
        "    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "    \"n_rows\": int(len(df)),\n",
        "    \"n_cols\": int(df.shape[1]),\n",
        "    \"present_cols\": list(df.columns),\n",
        "    \"expected_cols\": expected_cols,\n",
        "    \"missing_cols\": missing,\n",
        "    \"extra_cols\": extra,\n",
        "    \"schema_ok\": schema_ok\n",
        "}\n",
        "with open(ARTIFACTS_DIR / \"schema_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(schema_report, f, indent=2)\n",
        "log.info(f\"Schema report written. OK? {schema_ok}\")\n",
        "\n",
        "# Quick dtype summary\n",
        "dtype_summary = df.dtypes.astype(str).to_dict()\n",
        "pd.Series(dtype_summary).to_csv(ARTIFACTS_DIR / \"dtype_summary.csv\")\n",
        "dtype_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Parse list-like fields & simple unit checks\n",
        "\n",
        "def parse_listlike(s):\n",
        "    \"\"\"Robust parser for list-like strings.\n",
        "    Tries literal_eval (e.g., \"['123','456']\"), falls back to comma split.\n",
        "    Returns list[str].\n",
        "    \"\"\"\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    s = str(s).strip()\n",
        "    if not s:\n",
        "        return []\n",
        "    # Try literal list\n",
        "    try:\n",
        "        v = ast.literal_eval(s)\n",
        "        if isinstance(v, (list, tuple)):\n",
        "            return [str(x).strip() for x in v]\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback: comma-separated\n",
        "    return [x.strip() for x in s.split(\",\") if x.strip()]\n",
        "\n",
        "for col in [\"book_id_list_en\",\"genres_str\",\"shelves_str\"]:\n",
        "    if col in df.columns:\n",
        "        df[col + \"_list\"] = df[col].apply(parse_listlike)\n",
        "\n",
        "# Minimal unit checks\n",
        "assert df[\"book_id_list_en_list\"].apply(lambda x: isinstance(x, list)).all(), \"book_id_list_en_list parse failed\"\n",
        "assert df[\"genres_str_list\"].apply(lambda x: isinstance(x, list)).all(), \"genres_str_list parse failed\"\n",
        "assert df[\"shelves_str_list\"].apply(lambda x: isinstance(x, list)).all(), \"shelves_str_list parse failed\"\n",
        "\n",
        "# Counts non-negative\n",
        "for c in [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]:\n",
        "    if c in df.columns:\n",
        "        assert (df[c] >= 0).all(), f\"Negative counts found in {c}\"\n",
        "\n",
        "# Save small preview\n",
        "df.head(50).to_csv(ARTIFACTS_DIR / \"parsed_preview.csv\", index=False)\n",
        "log.info(\"Parsing complete and basic unit checks passed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Heavy-tail visuals: CCDF and log-binned histograms\n",
        "from math import ceil\n",
        "\n",
        "def plot_ccdf(x, title, fname):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    x = x[x >= 0]\n",
        "    x_sorted = np.sort(x)\n",
        "    n = len(x_sorted)\n",
        "    if n == 0:\n",
        "        log.warning(f\"No data for {title}\")\n",
        "        return\n",
        "    y = 1.0 - np.arange(1, n+1)/n\n",
        "    plt.figure()\n",
        "    plt.loglog(x_sorted, y, marker='.', linestyle='none')\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"CCDF P(X>=x)\")\n",
        "    plt.title(title + \" — Empirical CCDF (log–log)\")\n",
        "    plt.grid(True, which=\"both\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTIFACTS_DIR / fname, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "def plot_log_binned_hist(x, title, fname, bins=50):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    x = x[x > 0]\n",
        "    if len(x) == 0:\n",
        "        log.warning(f\"No positive data for {title}\")\n",
        "        return\n",
        "    # Log-spaced bins for visualization ONLY (do not fit on binned data)\n",
        "    xmin, xmax = x.min(), x.max()\n",
        "    edges = np.logspace(np.log10(xmin), np.log10(xmax), bins)\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=edges, density=True)\n",
        "    plt.xscale(\"log\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.xlabel(\"x (log)\")\n",
        "    plt.ylabel(\"Density (log)\")\n",
        "    plt.title(title + \" — Log-binned histogram (for visualization only)\")\n",
        "    plt.grid(True, which=\"both\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTIFACTS_DIR / (\"hist_\" + fname), dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "targets = [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]\n",
        "for var in targets:\n",
        "    if var in df.columns:\n",
        "        x = df[var].values\n",
        "        plot_ccdf(x, f\"{var}\", f\"ccdf_{var}.png\")\n",
        "        plot_log_binned_hist(x, f\"{var}\", f\"{var}.png\")\n",
        "log.info(\"Heavy-tail visualizations saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] CSN (2009) discrete power-law fits & model comparison (via `powerlaw`)\n",
        "# This cell uses the `powerlaw` package (Alstott et al., 2014).\n",
        "# If not installed, install in your environment: `pip install powerlaw`\n",
        "\n",
        "try:\n",
        "    import powerlaw\n",
        "    HAVE_POWERLAW = True\n",
        "except Exception as e:\n",
        "    HAVE_POWERLAW = False\n",
        "    log.warning(\"`powerlaw` not available. Install with `pip install powerlaw` to enable CSN fits.\")\n",
        "\n",
        "def csn_fit_report(x_raw, varname):\n",
        "    if not HAVE_POWERLAW:\n",
        "        return None\n",
        "    x = np.asarray(x_raw, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    # CSN tail model for counts: use strictly positive support\n",
        "    x = x[x >= 1]\n",
        "    if len(x) < 50:\n",
        "        log.warning(f\"{varname}: too few positive observations for tail fitting ({len(x)}).\")\n",
        "        return None\n",
        "    fit = powerlaw.Fit(x, discrete=True, estimate_discrete=True, verbose=False)\n",
        "    pl = fit.power_law\n",
        "    # Likelihood ratio tests vs alternatives\n",
        "    comps = {}\n",
        "    for alt in [\"lognormal\",\"exponential\",\"truncated_power_law\",\"stretched_exponential\"]:\n",
        "        try:\n",
        "            R, p = fit.distribution_compare('power_law', alt)\n",
        "            comps[alt] = {\"LR\": float(R), \"p\": float(p)}\n",
        "        except Exception as e:\n",
        "            comps[alt] = {\"LR\": None, \"p\": None}\n",
        "    report = {\n",
        "        \"var\": varname,\n",
        "        \"n_positive\": int(len(x)),\n",
        "        \"xmin\": float(pl.xmin),\n",
        "        \"alpha\": float(pl.alpha),\n",
        "        \"D_KS\": float(fit.D),\n",
        "        # Note: `powerlaw`'s gof p-value estimation can be computationally heavy; \n",
        "        # here we use the default KS; for full GOF bootstrap, see docs.\n",
        "        \"tail_fraction\": float((x >= pl.xmin).mean()),\n",
        "        \"comparisons\": comps,\n",
        "    }\n",
        "    return report\n",
        "\n",
        "csn_reports = []\n",
        "for var in [\"ratings_count_sum\",\"text_reviews_count_sum\",\"author_ratings_count\"]:\n",
        "    if var in df.columns:\n",
        "        rep = csn_fit_report(df[var].values, var)\n",
        "        if rep:\n",
        "            csn_reports.append(rep)\n",
        "\n",
        "if csn_reports:\n",
        "    with open(ARTIFACTS_DIR / \"csn_powerlaw_reports.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(csn_reports, f, indent=2)\n",
        "    log.info(\"CSN reports saved to csn_powerlaw_reports.json\")\n",
        "else:\n",
        "    log.info(\"CSN reports not generated (missing powerlaw or insufficient data).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Overdispersion tests: Dean–Lawless (Pearson chi-square) & Cameron–Trivedi (auxiliary OLS)\n",
        "# Requires statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def fit_poisson(y, X):\n",
        "    X_ = sm.add_constant(X, has_constant='add')\n",
        "    model = sm.GLM(y, X_, family=sm.families.Poisson())\n",
        "    res = model.fit()\n",
        "    return res\n",
        "\n",
        "def dean_lawless_test(res):\n",
        "    # Pearson chi-square should have E ≈ df and Var ≈ 2*df under Poisson\n",
        "    chi2 = res.pearson_chi2\n",
        "    df = res.df_resid\n",
        "    z = (chi2 - df) / math.sqrt(2.0*df) if df > 0 else np.nan\n",
        "    # two-sided p-value from N(0,1)\n",
        "    from math import erf, sqrt\n",
        "    p = 2*(1 - 0.5*(1 + erf(abs(z)/sqrt(2))))\n",
        "    return {\"pearson_chi2\": chi2, \"df\": df, \"z\": z, \"p_two_sided\": p}\n",
        "\n",
        "def cameron_trivedi_test(y, mu):\n",
        "    # Following auxiliary regression: Y* = ((y - mu)^2 - y) / mu  onto mu (no intercept)\n",
        "    # Reference: Cameron & Trivedi (1990); see also CRAN overdisp vignette\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    mu = np.asarray(mu, dtype=float)\n",
        "    mask = np.isfinite(y) & np.isfinite(mu) & (mu > 0)\n",
        "    y = y[mask]; mu = mu[mask]\n",
        "    y_star = ((y - mu)**2 - y) / mu\n",
        "    X_aux = mu.reshape(-1,1)  # no intercept\n",
        "    aux_res = sm.OLS(y_star, X_aux).fit()\n",
        "    alpha_hat = aux_res.params[0]\n",
        "    t_stat = aux_res.tvalues[0]\n",
        "    p_val = aux_res.pvalues[0]\n",
        "    return {\"alpha_hat\": alpha_hat, \"t\": t_stat, \"p\": p_val, \"n\": int(mask.sum())}\n",
        "\n",
        "# Example design matrix: simple intercept-only model for baseline\n",
        "targets = [\"ratings_count_sum\",\"text_reviews_count_sum\"]\n",
        "X_baseline = pd.DataFrame({\"intercept_only\": np.ones(len(df))})\n",
        "\n",
        "overdisp_results = []\n",
        "for var in targets:\n",
        "    if var in df.columns:\n",
        "        y = df[var].values\n",
        "        res = fit_poisson(y, X_baseline)\n",
        "        dl = dean_lawless_test(res)\n",
        "        ct = cameron_trivedi_test(y, res.fittedvalues)\n",
        "        overdisp_results.append({\"var\": var, \"dean_lawless\": dl, \"cameron_trivedi\": ct})\n",
        "\n",
        "with open(ARTIFACTS_DIR / \"overdispersion_tests.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(overdisp_results, f, indent=2)\n",
        "log.info(\"Overdispersion tests saved to overdispersion_tests.json\")\n",
        "overdisp_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outputs generated\n",
        "- `audit_artifacts/schema_report.json` — column presence & dtype summary\n",
        "- `audit_artifacts/dtype_summary.csv` — dtypes\n",
        "- `audit_artifacts/parsed_preview.csv` — first 50 rows after parsing\n",
        "- `audit_artifacts/ccdf_*.png`, `audit_artifacts/hist_*.png` — heavy-tail visuals\n",
        "- `audit_artifacts/csn_powerlaw_reports.json` — (if `powerlaw` installed) CSN fits\n",
        "- `audit_artifacts/overdispersion_tests.json` — Dean–Lawless & Cameron–Trivedi test results\n",
        "- `audit_artifacts/excluded_shelves.csv` — shelves flagged by leakage filters\n",
        "\n",
        "> Note: **Do not** fit lines to binned histograms. Use CSN MLE + KS (and LR comparisons) for tail inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code] Apply leakage filters (regexes) to shelves\n",
        "import yaml, re\n",
        "\n",
        "filters = {}\n",
        "with open(\"shelf_filters.yml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    filters = yaml.safe_load(f)\n",
        "\n",
        "patterns = []\n",
        "for group, exprs in filters.items():\n",
        "    for e in exprs:\n",
        "        try:\n",
        "            patterns.append((group, re.compile(e, flags=re.IGNORECASE)))\n",
        "        except re.error as ex:\n",
        "            log.warning(f\"Invalid regex in group {group}: {e} ({ex})\")\n",
        "\n",
        "def is_excluded_shelf(s):\n",
        "    s = str(s).strip()\n",
        "    for g, pat in patterns:\n",
        "        if pat.search(s):\n",
        "            return True, g\n",
        "    return False, None\n",
        "\n",
        "shelves = df[\"shelves_str_list\"].explode().dropna().astype(str).unique().tolist()\n",
        "rows = []\n",
        "for s in shelves:\n",
        "    exc, group = is_excluded_shelf(s)\n",
        "    if exc:\n",
        "        rows.append({\"shelf\": s, \"group\": group})\n",
        "\n",
        "excluded_df = pd.DataFrame(rows).sort_values([\"group\",\"shelf\"])\n",
        "excluded_df.to_csv(ARTIFACTS_DIR / \"excluded_shelves.csv\", index=False)\n",
        "log.info(f\"Excluded {len(excluded_df)} unique shelves (see excluded_shelves.csv).\")\n",
        "excluded_df.head(20)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
