{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Goodreads Shelf Normalization and Clustering\n",
        "\n",
        "This notebook focuses on cleaning and normalizing reader-created shelf tags from Goodreads data.\n",
        "We'll group similar/synonymous shelf names and assign umbrella terms for each cluster.\n",
        "\n",
        "## Objectives\n",
        "1. Load and explore shelf data structure\n",
        "2. Analyze shelf frequency and patterns\n",
        "3. Implement clustering/normalization logic\n",
        "4. Validate and export normalized shelf mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Loaded main final dataset: 53349 books\n",
            "INFO:__main__:Dropped columns: []\n",
            "INFO:__main__:Replaced NaN values in series_works_count_numeric with 'stand_alone'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape after dropping columns: (53349, 19)\n",
            "\n",
            "Remaining column names:\n",
            "['work_id', 'book_id_list_en', 'title', 'publication_year', 'num_pages_median', 'description', 'language_codes_en', 'author_id', 'author_name', 'author_average_rating', 'author_ratings_count', 'series_id', 'series_title', 'ratings_count_sum', 'text_reviews_count_sum', 'average_rating_weighted_mean', 'genres_str', 'shelves_str', 'series_works_count_numeric']\n",
            "\n",
            "Data types:\n",
            "work_id                           int64\n",
            "book_id_list_en                  object\n",
            "title                            object\n",
            "publication_year                  int64\n",
            "num_pages_median                float64\n",
            "description                      object\n",
            "language_codes_en                object\n",
            "author_id                         int64\n",
            "author_name                      object\n",
            "author_average_rating           float64\n",
            "author_ratings_count              int64\n",
            "series_id                        object\n",
            "series_title                     object\n",
            "ratings_count_sum                 int64\n",
            "text_reviews_count_sum            int64\n",
            "average_rating_weighted_mean    float64\n",
            "genres_str                       object\n",
            "shelves_str                      object\n",
            "series_works_count_numeric       object\n",
            "dtype: object\n",
            "\n",
            "============================================================\n",
            "COLUMN: work_id\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üîë ID COLUMN - Excluded from numerical analysis\n",
            "üîë ID COLUMN - Basic stats skipped\n",
            "Unique values: 53349\n",
            "\n",
            "============================================================\n",
            "COLUMN: book_id_list_en\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üîë ID COLUMN - Excluded from numerical analysis\n",
            "Unique values: 53349\n",
            "Sample values:\n",
            "  [1] ['9416', '227650', '9423', '6088685', '19826270', '2574859', '13576133', '736396', '8724433', '32084...\n",
            "  [2] ['3462', '6338758', '289110', '6386960', '17787192']\n",
            "  [3] ['110391', '6077588', '25322247', '1859059', '298367', '5466440', '11793041', '23460960', '32177084'...\n",
            "  [4] ['861326', '6077587', '25322244', '353066', '9138773', '7961903', '32812329']\n",
            "  [5] ['22649', '22655', '31107', '6560878', '2576684', '12863586']\n",
            "  [6] ['469901', '11725217', '847901', '759501', '5410943']\n",
            "  [7] ['815150', '112753', '8130560', '6988762', '1982705', '344553', '22093943']\n",
            "  [8] ['89160', '6699943', '268595', '6146611', '7909185', '3062807', '2494210', '3062808', '6994134', '30...\n",
            "  [9] ['17781', '682359', '608949', '2875448']\n",
            "  [10] ['213975', '6660825', '531717', '10334321', '2097994', '8018051', '13553494', '1280346', '3062909', ...\n",
            "  ‚ö†Ô∏è  Contains list-like strings - may need parsing\n",
            "String length stats: min=8, max=1049, mean=21.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: title\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 46352\n",
            "Sample values:\n",
            "  [1] Confessions of a Shopaholic\n",
            "  [2] The Rescue\n",
            "  [3] The Duke and I\n",
            "  [4] The Viscount Who Loved Me\n",
            "  [5] Bookends\n",
            "  [6] Mr. Perfect\n",
            "  [7] The Highlander's Touch\n",
            "  [8] Judgment in Death\n",
            "  [9] Heart of the Sea\n",
            "  [10] Witness in Death\n",
            "String length stats: min=1, max=128, mean=16.5\n",
            "\n",
            "============================================================\n",
            "COLUMN: publication_year\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 2012.727736227483\n",
            "  std: 3.2824543292995014\n",
            "  min: 2000.0\n",
            "  25%: 2012.0\n",
            "  50%: 2013.0\n",
            "  75%: 2015.0\n",
            "  max: 2017.0\n",
            "Value counts (low cardinality - 18 unique values):\n",
            "  2013: 8998 (16.9%)\n",
            "  2014: 8565 (16.1%)\n",
            "  2015: 7072 (13.3%)\n",
            "  2012: 6318 (11.8%)\n",
            "  2016: 5778 (10.8%)\n",
            "  2017: 3682 (6.9%)\n",
            "  2011: 3614 (6.8%)\n",
            "  2010: 2172 (4.1%)\n",
            "  2009: 1663 (3.1%)\n",
            "  2008: 1206 (2.3%)\n",
            "\n",
            "============================================================\n",
            "COLUMN: num_pages_median\n",
            "============================================================\n",
            "Data type: float64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 260.72378113929034\n",
            "  std: 100.93586926638137\n",
            "  min: 90.0\n",
            "  25%: 187.5\n",
            "  50%: 256.0\n",
            "  75%: 328.0\n",
            "  max: 980.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: description\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 53316\n",
            "Sample values:\n",
            "  [1] Unabridged audible download; approximately 11 hours 45 minutes If you've ever paid off one credit ca...\n",
            "  [2] When confronted by raging fires or deadly accidents, volunteer fireman Taylor McAden feels compelled...\n",
            "  [3] Can there be any greater challenge to London's Ambitious Mamas than an unmarried duke? --Lady Whistl...\n",
            "  [4] Alternate cover for ISBN: 0380815575/9780380815579 1814 promises to be another eventful season, but ...\n",
            "  [5] On the heels of her national bestsellers Jemima Jand Mr. Maybe, British sensation Jane Green deliver...\n",
            "  [6] What would make the perfect man?That's the delicious topic heating up the proceedings at a certain t...\n",
            "  [7] A Warrior of Immortal Powers He was a mighty Scottish warrior who lived in a world bound by ancient ...\n",
            "  [8] 'She stood in Purgatory and studied death. The blood and the gore of it, the ferocity of its glee. I...\n",
            "  [9] The breathtaking conclusion to the New York Times bestselling trilogy that began with Jewels of the ...\n",
            "  [10] LENGTH -- 10 hrs and 51 mins Opening night at New York's New Globe Theater turns from stage scene to...\n",
            "String length stats: min=4, max=14363, mean=979.4\n",
            "\n",
            "============================================================\n",
            "COLUMN: language_codes_en\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 1\n",
            "Sample values:\n",
            "  [1] eng\n",
            "  [2] eng\n",
            "  [3] eng\n",
            "  [4] eng\n",
            "  [5] eng\n",
            "  [6] eng\n",
            "  [7] eng\n",
            "  [8] eng\n",
            "  [9] eng\n",
            "  [10] eng\n",
            "String length stats: min=3, max=3, mean=3.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: author_id\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üîë ID COLUMN - Excluded from numerical analysis\n",
            "üîë ID COLUMN - Basic stats skipped\n",
            "Unique values: 17810\n",
            "\n",
            "============================================================\n",
            "COLUMN: author_name\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 17810\n",
            "Sample values:\n",
            "  [1] Sophie Kinsella\n",
            "  [2] Nicholas Sparks\n",
            "  [3] Julia Quinn\n",
            "  [4] Julia Quinn\n",
            "  [5] Jane Green\n",
            "  [6] Linda Howard\n",
            "  [7] Karen Marie Moning\n",
            "  [8] J.D. Robb\n",
            "  [9] Nora Roberts\n",
            "  [10] J.D. Robb\n",
            "String length stats: min=2, max=50, mean=12.9\n",
            "\n",
            "============================================================\n",
            "COLUMN: author_average_rating\n",
            "============================================================\n",
            "Data type: float64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 3.9088455266265534\n",
            "  std: 0.25981381851075186\n",
            "  min: 1.27\n",
            "  25%: 3.75\n",
            "  50%: 3.92\n",
            "  75%: 4.08\n",
            "  max: 5.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: author_ratings_count\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 48181.19623610564\n",
            "  std: 193397.0028438366\n",
            "  min: 1.0\n",
            "  25%: 843.0\n",
            "  50%: 5101.0\n",
            "  75%: 25548.0\n",
            "  max: 5280268.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: series_id\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üîë ID COLUMN - Excluded from numerical analysis\n",
            "Unique values: 36066\n",
            "Sample values:\n",
            "  [1] 165735.0\n",
            "  [2] stand_alone\n",
            "  [3] 153045.0\n",
            "  [4] 144491.0\n",
            "  [5] stand_alone\n",
            "  [6] stand_alone\n",
            "  [7] 288256.0\n",
            "  [8] 145625.0\n",
            "  [9] 167116.0\n",
            "  [10] 162517.0\n",
            "String length stats: min=8, max=11, mean=9.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: series_title\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 17013\n",
            "Sample values:\n",
            "  [1] Shopaholic\n",
            "  [2] stand_alone\n",
            "  [3] Bridgertons\n",
            "  [4] Bridgertons\n",
            "  [5] stand_alone\n",
            "  [6] stand_alone\n",
            "  [7] Highlander\n",
            "  [8] In Death\n",
            "  [9] Gallaghers of Ardmore\n",
            "  [10] In Death\n",
            "String length stats: min=2, max=76, mean=13.7\n",
            "\n",
            "============================================================\n",
            "COLUMN: ratings_count_sum\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 1734.0819134379276\n",
            "  std: 14322.839048619157\n",
            "  min: 1.0\n",
            "  25%: 48.0\n",
            "  50%: 182.0\n",
            "  75%: 802.0\n",
            "  max: 1686868.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: text_reviews_count_sum\n",
            "============================================================\n",
            "Data type: int64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 141.86205927008942\n",
            "  std: 739.997994905451\n",
            "  min: 0.0\n",
            "  25%: 11.0\n",
            "  50%: 32.0\n",
            "  75%: 97.0\n",
            "  max: 74298.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: average_rating_weighted_mean\n",
            "============================================================\n",
            "Data type: float64\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "üìä NUMERICAL COLUMN - Valid for analysis\n",
            "Basic stats:\n",
            "  count: 53349.0\n",
            "  mean: 3.9148518636413057\n",
            "  std: 0.34712338801084197\n",
            "  min: 1.27\n",
            "  25%: 3.71\n",
            "  50%: 3.93\n",
            "  75%: 4.15\n",
            "  max: 5.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: genres_str\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 137\n",
            "Sample values:\n",
            "  [1] fiction,romance,young adult\n",
            "  [2] fiction,mystery,romance,young adult\n",
            "  [3] biography,fiction,historical fiction,history,romance\n",
            "  [4] biography,fiction,historical fiction,history,romance\n",
            "  [5] fiction,romance\n",
            "  [6] fiction,mystery,romance\n",
            "  [7] biography,fantasy,fiction,historical fiction,history,paranormal,romance\n",
            "  [8] fantasy,fiction,mystery,paranormal,romance\n",
            "  [9] biography,fantasy,fiction,historical fiction,history,mystery,paranormal,romance\n",
            "  [10] fantasy,fiction,mystery,paranormal,romance\n",
            "String length stats: min=7, max=107, mean=28.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: shelves_str\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 53346\n",
            "Sample values:\n",
            "  [1] 3-stars,5-stars,abandoned,adult-fiction,audio,audiobook,audiobooks,beach-read,beach-reads,book-club,...\n",
            "  [2] 2000,2001,2012-reads,adult,adult-fiction,already-read,audio,audio-book,audio-books,audiobook,audiobo...\n",
            "  [3] 19th-century,1st-in-series,2012-reads,2016-reads,3-stars,4-stars,5-stars,adult,adult-fiction,adult-r...\n",
            "  [4] 1,19th-century,2016-reads,3-stars,4-stars,5-stars,adult,adult-fiction,adult-romance,all-time-favorit...\n",
            "  [5] 2002,2003,2004,2005,2006,5-stars,abandoned,adult,adult-fiction,audiobooks,beach-read,beach-reads,bea...\n",
            "  [6] 3-stars,4-stars,5-star,5-stars,aar-top-100,action,adult,adult-fiction,adult-romance,all-time-favorit...\n",
            "  [7] 4-star,4-stars,5-stars,adult,adult-fiction,adult-romance,alpha-male,audible,audio,audio-book,audio-b...\n",
            "  [8] 2015-reads,4-stars,5-stars,action,adult,adult-fiction,audible,audio,audio-book,audio-books,audiobook...\n",
            "  [9] adult-fiction,adult-romance,audible,audio,audiobook,audiobooks,author-nora-roberts,books,books-i-hav...\n",
            "  [10] 4-stars,5-stars,action,adult,adult-fiction,audible,audio,audio-book,audio-books,audiobook,audiobooks...\n",
            "String length stats: min=7, max=2283, mean=1019.0\n",
            "\n",
            "============================================================\n",
            "COLUMN: series_works_count_numeric\n",
            "============================================================\n",
            "Data type: object\n",
            "Non-null count: 53349 / 53349 (100.0%)\n",
            "Null count: 0 (0.0%)\n",
            "Unique values: 70\n",
            "Sample values:\n",
            "  [1] 12.0\n",
            "  [2] stand_alone\n",
            "  [3] 19.0\n",
            "  [4] 19.0\n",
            "  [5] stand_alone\n",
            "  [6] stand_alone\n",
            "  [7] 12.0\n",
            "  [8] 115.0\n",
            "  [9] 6.0\n",
            "  [10] 115.0\n",
            "String length stats: min=3, max=11, mean=5.7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>work_id</th>\n",
              "      <th>book_id_list_en</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>num_pages_median</th>\n",
              "      <th>description</th>\n",
              "      <th>language_codes_en</th>\n",
              "      <th>author_id</th>\n",
              "      <th>author_name</th>\n",
              "      <th>author_average_rating</th>\n",
              "      <th>author_ratings_count</th>\n",
              "      <th>series_id</th>\n",
              "      <th>series_title</th>\n",
              "      <th>ratings_count_sum</th>\n",
              "      <th>text_reviews_count_sum</th>\n",
              "      <th>average_rating_weighted_mean</th>\n",
              "      <th>genres_str</th>\n",
              "      <th>shelves_str</th>\n",
              "      <th>series_works_count_numeric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3237433</td>\n",
              "      <td>['9416', '227650', '9423', '6088685', '1982627...</td>\n",
              "      <td>Confessions of a Shopaholic</td>\n",
              "      <td>2000</td>\n",
              "      <td>320.0</td>\n",
              "      <td>Unabridged audible download; approximately 11 ...</td>\n",
              "      <td>eng</td>\n",
              "      <td>6160</td>\n",
              "      <td>Sophie Kinsella</td>\n",
              "      <td>3.74</td>\n",
              "      <td>2169284</td>\n",
              "      <td>165735.0</td>\n",
              "      <td>Shopaholic</td>\n",
              "      <td>555675</td>\n",
              "      <td>10488</td>\n",
              "      <td>3.62</td>\n",
              "      <td>fiction,romance,young adult</td>\n",
              "      <td>3-stars,5-stars,abandoned,adult-fiction,audio,...</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1268663</td>\n",
              "      <td>['3462', '6338758', '289110', '6386960', '1778...</td>\n",
              "      <td>The Rescue</td>\n",
              "      <td>2000</td>\n",
              "      <td>372.0</td>\n",
              "      <td>When confronted by raging fires or deadly acci...</td>\n",
              "      <td>eng</td>\n",
              "      <td>2345</td>\n",
              "      <td>Nicholas Sparks</td>\n",
              "      <td>4.06</td>\n",
              "      <td>4600277</td>\n",
              "      <td>stand_alone</td>\n",
              "      <td>stand_alone</td>\n",
              "      <td>148062</td>\n",
              "      <td>3150</td>\n",
              "      <td>4.10</td>\n",
              "      <td>fiction,mystery,romance,young adult</td>\n",
              "      <td>2000,2001,2012-reads,adult,adult-fiction,alrea...</td>\n",
              "      <td>stand_alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>846763</td>\n",
              "      <td>['110391', '6077588', '25322247', '1859059', '...</td>\n",
              "      <td>The Duke and I</td>\n",
              "      <td>2000</td>\n",
              "      <td>371.0</td>\n",
              "      <td>Can there be any greater challenge to London's...</td>\n",
              "      <td>eng</td>\n",
              "      <td>63898</td>\n",
              "      <td>Julia Quinn</td>\n",
              "      <td>3.98</td>\n",
              "      <td>567004</td>\n",
              "      <td>153045.0</td>\n",
              "      <td>Bridgertons</td>\n",
              "      <td>61848</td>\n",
              "      <td>2444</td>\n",
              "      <td>4.11</td>\n",
              "      <td>biography,fiction,historical fiction,history,r...</td>\n",
              "      <td>19th-century,1st-in-series,2012-reads,2016-rea...</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3363</td>\n",
              "      <td>['861326', '6077587', '25322244', '353066', '9...</td>\n",
              "      <td>The Viscount Who Loved Me</td>\n",
              "      <td>2000</td>\n",
              "      <td>381.0</td>\n",
              "      <td>Alternate cover for ISBN: 0380815575/978038081...</td>\n",
              "      <td>eng</td>\n",
              "      <td>63898</td>\n",
              "      <td>Julia Quinn</td>\n",
              "      <td>3.98</td>\n",
              "      <td>567004</td>\n",
              "      <td>144491.0</td>\n",
              "      <td>Bridgertons</td>\n",
              "      <td>38086</td>\n",
              "      <td>1404</td>\n",
              "      <td>4.19</td>\n",
              "      <td>biography,fiction,historical fiction,history,r...</td>\n",
              "      <td>1,19th-century,2016-reads,3-stars,4-stars,5-st...</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2363</td>\n",
              "      <td>['22649', '22655', '31107', '6560878', '257668...</td>\n",
              "      <td>Bookends</td>\n",
              "      <td>2000</td>\n",
              "      <td>368.0</td>\n",
              "      <td>On the heels of her national bestsellers Jemim...</td>\n",
              "      <td>eng</td>\n",
              "      <td>12915</td>\n",
              "      <td>Jane Green</td>\n",
              "      <td>3.58</td>\n",
              "      <td>502125</td>\n",
              "      <td>stand_alone</td>\n",
              "      <td>stand_alone</td>\n",
              "      <td>34139</td>\n",
              "      <td>842</td>\n",
              "      <td>3.70</td>\n",
              "      <td>fiction,romance</td>\n",
              "      <td>2002,2003,2004,2005,2006,5-stars,abandoned,adu...</td>\n",
              "      <td>stand_alone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   work_id                                    book_id_list_en  \\\n",
              "0  3237433  ['9416', '227650', '9423', '6088685', '1982627...   \n",
              "1  1268663  ['3462', '6338758', '289110', '6386960', '1778...   \n",
              "2   846763  ['110391', '6077588', '25322247', '1859059', '...   \n",
              "3     3363  ['861326', '6077587', '25322244', '353066', '9...   \n",
              "4     2363  ['22649', '22655', '31107', '6560878', '257668...   \n",
              "\n",
              "                         title  publication_year  num_pages_median  \\\n",
              "0  Confessions of a Shopaholic              2000             320.0   \n",
              "1                   The Rescue              2000             372.0   \n",
              "2               The Duke and I              2000             371.0   \n",
              "3    The Viscount Who Loved Me              2000             381.0   \n",
              "4                     Bookends              2000             368.0   \n",
              "\n",
              "                                         description language_codes_en  \\\n",
              "0  Unabridged audible download; approximately 11 ...               eng   \n",
              "1  When confronted by raging fires or deadly acci...               eng   \n",
              "2  Can there be any greater challenge to London's...               eng   \n",
              "3  Alternate cover for ISBN: 0380815575/978038081...               eng   \n",
              "4  On the heels of her national bestsellers Jemim...               eng   \n",
              "\n",
              "   author_id      author_name  author_average_rating  author_ratings_count  \\\n",
              "0       6160  Sophie Kinsella                   3.74               2169284   \n",
              "1       2345  Nicholas Sparks                   4.06               4600277   \n",
              "2      63898      Julia Quinn                   3.98                567004   \n",
              "3      63898      Julia Quinn                   3.98                567004   \n",
              "4      12915       Jane Green                   3.58                502125   \n",
              "\n",
              "     series_id series_title  ratings_count_sum  text_reviews_count_sum  \\\n",
              "0     165735.0   Shopaholic             555675                   10488   \n",
              "1  stand_alone  stand_alone             148062                    3150   \n",
              "2     153045.0  Bridgertons              61848                    2444   \n",
              "3     144491.0  Bridgertons              38086                    1404   \n",
              "4  stand_alone  stand_alone              34139                     842   \n",
              "\n",
              "   average_rating_weighted_mean  \\\n",
              "0                          3.62   \n",
              "1                          4.10   \n",
              "2                          4.11   \n",
              "3                          4.19   \n",
              "4                          3.70   \n",
              "\n",
              "                                          genres_str  \\\n",
              "0                        fiction,romance,young adult   \n",
              "1                fiction,mystery,romance,young adult   \n",
              "2  biography,fiction,historical fiction,history,r...   \n",
              "3  biography,fiction,historical fiction,history,r...   \n",
              "4                                    fiction,romance   \n",
              "\n",
              "                                         shelves_str  \\\n",
              "0  3-stars,5-stars,abandoned,adult-fiction,audio,...   \n",
              "1  2000,2001,2012-reads,adult,adult-fiction,alrea...   \n",
              "2  19th-century,1st-in-series,2012-reads,2016-rea...   \n",
              "3  1,19th-century,2016-reads,3-stars,4-stars,5-st...   \n",
              "4  2002,2003,2004,2005,2006,5-stars,abandoned,adu...   \n",
              "\n",
              "  series_works_count_numeric  \n",
              "0                       12.0  \n",
              "1                stand_alone  \n",
              "2                       19.0  \n",
              "3                       19.0  \n",
              "4                stand_alone  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "### üîÑ Dataset Loading and Column Management\n",
        "\n",
        "# Load dataset - using absolute path from project root\n",
        "project_root = os.path.abspath(\"../../../\")  # Go up 3 levels from src/data_audit/notebooks/\n",
        "main_final_path = os.path.join(project_root, \"data\", \"processed\", \"romance_books_main_final.csv\")\n",
        "\n",
        "# Verify file exists before loading\n",
        "if not os.path.exists(main_final_path):\n",
        "    raise FileNotFoundError(f\"Dataset not found at: {main_final_path}\")\n",
        "\n",
        "main_final = pd.read_csv(main_final_path)\n",
        "logger.info(f\"Loaded main final dataset: {len(main_final)} books\")\n",
        "\n",
        "# Drop specified columns\n",
        "columns_to_drop = ['series_works_count', 'popular_shelves', 'genres', 'decade', \n",
        "                   'book_length_category', 'rating_category', 'popularity_category', \n",
        "                   'has_collection_indicators']\n",
        "main_final = main_final.drop(columns=columns_to_drop, errors='ignore')\n",
        "logger.info(f\"Dropped columns: {[col for col in columns_to_drop if col in main_final.columns]}\")\n",
        "\n",
        "# Clean series_works_count_numeric: replace NaN with 'stand_alone'\n",
        "main_final['series_works_count_numeric'] = main_final['series_works_count_numeric'].fillna('stand_alone')\n",
        "logger.info(f\"Replaced NaN values in series_works_count_numeric with 'stand_alone'\")\n",
        "\n",
        "### üìã Basic Dataset Information\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Dataset shape after dropping columns: {main_final.shape}\")\n",
        "print(f\"\\nRemaining column names:\")\n",
        "print(main_final.columns.tolist())\n",
        "print(f\"\\nData types:\")\n",
        "print(main_final.dtypes)\n",
        "\n",
        "### üîç Detailed Column Investigation\n",
        "\n",
        "# Define ID columns to exclude from numerical analysis\n",
        "id_columns = ['work_id', 'book_id_list_en', 'author_id', 'series_id']\n",
        "\n",
        "for col in main_final.columns:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"COLUMN: {col}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Basic info\n",
        "    print(f\"Data type: {main_final[col].dtype}\")\n",
        "    print(f\"Non-null count: {main_final[col].count()} / {len(main_final)} ({main_final[col].count()/len(main_final)*100:.1f}%)\")\n",
        "    print(f\"Null count: {main_final[col].isnull().sum()} ({main_final[col].isnull().sum()/len(main_final)*100:.1f}%)\")\n",
        "    \n",
        "    # Mark ID columns\n",
        "    if col in id_columns:\n",
        "        print(\"üîë ID COLUMN - Excluded from numerical analysis\")\n",
        "    \n",
        "    # Type-specific analysis\n",
        "    if main_final[col].dtype in ['object']:\n",
        "        print(f\"Unique values: {main_final[col].nunique()}\")\n",
        "        print(f\"Sample values:\")\n",
        "        sample_values = main_final[col].dropna().head(10).tolist()\n",
        "        for i, val in enumerate(sample_values):\n",
        "            val_str = str(val)\n",
        "            if len(val_str) > 100:\n",
        "                val_str = val_str[:100] + \"...\"\n",
        "            print(f\"  [{i+1}] {val_str}\")\n",
        "        \n",
        "        # Check for list-like strings\n",
        "        if any(main_final[col].dropna().astype(str).str.startswith('[').head(100)):\n",
        "            print(\"  ‚ö†Ô∏è  Contains list-like strings - may need parsing\")\n",
        "        \n",
        "        # Value length distribution for string columns\n",
        "        lengths = main_final[col].dropna().astype(str).str.len()\n",
        "        print(f\"String length stats: min={lengths.min()}, max={lengths.max()}, mean={lengths.mean():.1f}\")\n",
        "        \n",
        "    elif main_final[col].dtype in ['int64', 'float64'] and col not in id_columns:\n",
        "        print(f\"üìä NUMERICAL COLUMN - Valid for analysis\")\n",
        "        print(f\"Basic stats:\")\n",
        "        stats = main_final[col].describe()\n",
        "        for stat_name, stat_val in stats.items():\n",
        "            print(f\"  {stat_name}: {stat_val}\")\n",
        "        \n",
        "        # Check for potential categorical numeric columns\n",
        "        unique_count = main_final[col].nunique()\n",
        "        if unique_count <= 20:\n",
        "            print(f\"Value counts (low cardinality - {unique_count} unique values):\")\n",
        "            vc = main_final[col].value_counts().head(10)\n",
        "            for val, count in vc.items():\n",
        "                print(f\"  {val}: {count} ({count/len(main_final)*100:.1f}%)\")\n",
        "    \n",
        "    elif main_final[col].dtype in ['int64', 'float64'] and col in id_columns:\n",
        "        print(f\"üîë ID COLUMN - Basic stats skipped\")\n",
        "        unique_count = main_final[col].nunique()\n",
        "        print(f\"Unique values: {unique_count}\")\n",
        "        \n",
        "    elif main_final[col].dtype in ['bool']:\n",
        "        print(f\"Boolean distribution:\")\n",
        "        vc = main_final[col].value_counts()\n",
        "        for val, count in vc.items():\n",
        "            print(f\"  {val}: {count} ({count/len(main_final)*100:.1f}%)\")\n",
        "\n",
        "### üìä Sample Data Preview\n",
        "\n",
        "main_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install rapidfuzz\n",
        "! pip install Unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CELL: UNIVERSAL STRING CANONICALIZATION (v1.1)\n",
        "# =============================================================================\n",
        "import re, time, json, unicodedata\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz  # pip install rapidfuzz\n",
        "from unidecode import unidecode  # pip install Unidecode\n",
        "\n",
        "print(f\"\\n[{time.strftime('%H:%M:%S')}] üîß CELL 2: UNIVERSAL STRING CANONICALIZATION (v1.1)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "CANONICAL_CONFIG = {\n",
        "    'normalize_case': True,\n",
        "    'remove_extra_whitespace': True,\n",
        "    'standardize_separators': True,\n",
        "    'fold_accents': True,\n",
        "    'map_variants': True,        # unify common aliases\n",
        "    'min_token_length': 1,\n",
        "    'max_token_length': 100\n",
        "}\n",
        "print(\"üìã CANONICALIZATION CONFIG:\", CANONICAL_CONFIG)\n",
        "\n",
        "# House-style replacements (extend as needed)\n",
        "ALIASES = {\n",
        "    \"&\": \" and \",\n",
        "    \"ya\": \"young adult\",\n",
        "    \"sci fi\": \"scifi\",\n",
        "    \"sci-fi\": \"scifi\",\n",
        "    \"favourite\": \"favorite\",\n",
        "    \"rom com\": \"romcom\",\n",
        "}\n",
        "RATING_RE = re.compile(r\"\\b([1-5])\\s*[- ]?\\s*star(s)?\\b\")\n",
        "YEARLIST_RE = re.compile(r\"\\b(19|20)\\d{2}(-reads)?\\b\")\n",
        "STATUS_SET = {\"to read\",\"to-read\",\"currently reading\",\"currently-reading\",\"did not finish\",\"dnf\",\"abandoned\"}\n",
        "FORMAT_SET = {\"audiobook\",\"audio book\",\"audio\",\"audible\",\"ebook\",\"e-book\",\"kindle\",\"paperback\",\"hardcover\"}\n",
        "\n",
        "def _normalize(s: str) -> str:\n",
        "    if not isinstance(s, str): return \"\"\n",
        "    x = s.strip()\n",
        "    if CANONICAL_CONFIG['fold_accents']:\n",
        "        x = unidecode(x)  # ASCII fold (caf√© -> cafe)\n",
        "    if CANONICAL_CONFIG['normalize_case']:\n",
        "        x = x.lower()\n",
        "    if CANONICAL_CONFIG['standardize_separators']:\n",
        "        x = re.sub(r\"[-_/]+\", \" \", x)\n",
        "        x = re.sub(r\"\\s+\", \" \", x)\n",
        "    if CANONICAL_CONFIG['map_variants']:\n",
        "        # light-weight replacements\n",
        "        for k, v in ALIASES.items():\n",
        "            x = x.replace(k, v)\n",
        "        x = re.sub(RATING_RE, r\"rating-\\1\", x)  # 5 stars -> rating-5\n",
        "    return x.strip()\n",
        "\n",
        "def canonicalize_tag(tag: str) -> str:\n",
        "    x = _normalize(tag)\n",
        "    if not x: return \"\"\n",
        "    # collapse obvious plurals (books -> book) while leaving proper nouns mostly intact\n",
        "    x = re.sub(r\"\\b(romances)\\b\", \"romance\", x)\n",
        "    x = re.sub(r\"\\b(historical romances)\\b\", \"historical romance\", x)\n",
        "    # keep within length constraints\n",
        "    if not (CANONICAL_CONFIG['min_token_length'] <= len(x) <= CANONICAL_CONFIG['max_token_length']):\n",
        "        return \"\"\n",
        "    return x\n",
        "\n",
        "# --- Vectorized extraction of shelves/genres ---\n",
        "def _split_comma_series(series: pd.Series) -> pd.Series:\n",
        "    return series.fillna(\"\").astype(str).str.split(\",\").explode().str.strip().replace(\"\", pd.NA).dropna()\n",
        "\n",
        "genres_series = _split_comma_series(main_final['genres_str'])\n",
        "shelves_series = _split_comma_series(main_final['shelves_str'])\n",
        "\n",
        "unique_genres = pd.Index(genres_series.unique())\n",
        "unique_shelves = pd.Index(shelves_series.unique())\n",
        "\n",
        "canon_genres = pd.Series({g: canonicalize_tag(g) for g in unique_genres})\n",
        "canon_shelves = pd.Series({s: canonicalize_tag(s) for s in unique_shelves})\n",
        "\n",
        "# Drop empties and compute compression\n",
        "canon_genres = canon_genres[canon_genres != \"\"]\n",
        "canon_shelves = canon_shelves[canon_shelves != \"\"]\n",
        "unique_canonical_genres = pd.Index(canon_genres.unique())\n",
        "unique_canonical_shelves = pd.Index(canon_shelves.unique())\n",
        "\n",
        "genre_compression_ratio = len(unique_canonical_genres) / len(unique_genres) if len(unique_genres) else 1.0\n",
        "shelf_compression_ratio = len(unique_canonical_shelves) / len(unique_shelves) if len(unique_shelves) else 1.0\n",
        "\n",
        "print(\"\\nüìä CANONICALIZATION RESULTS\")\n",
        "print(\"-\"*40)\n",
        "print(f\"Genres:   original={len(unique_genres):,}  canonical={len(unique_canonical_genres):,}  compression={genre_compression_ratio:.3f}\")\n",
        "print(f\"Shelves:  original={len(unique_shelves):,} canonical={len(unique_canonical_shelves):,} compression={shelf_compression_ratio:.3f}\")\n",
        "\n",
        "# Persist mappings\n",
        "outputs_dir = Path(\"romance-novel-nlp-research/src/eda_analysis/outputs\")\n",
        "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pd.DataFrame({'original': canon_genres.index, 'canonical': canon_genres.values}).to_csv(outputs_dir/\"genre_canonical_mappings.csv\", index=False)\n",
        "pd.DataFrame({'original': canon_shelves.index, 'canonical': canon_shelves.values}).to_csv(outputs_dir/\"shelf_canonical_mappings.csv\", index=False)\n",
        "\n",
        "meta = {\n",
        "  'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "  'config': CANONICAL_CONFIG,\n",
        "  'stats': {\n",
        "      'genres': {\n",
        "          'original_count': int(len(unique_genres)),\n",
        "          'canonical_count': int(len(unique_canonical_genres)),\n",
        "          'compression_ratio': float(genre_compression_ratio),\n",
        "          'duplicates_eliminated': int(len(unique_genres)-len(unique_canonical_genres)),\n",
        "      },\n",
        "      'shelves': {\n",
        "          'original_count': int(len(unique_shelves)),\n",
        "          'canonical_count': int(len(unique_canonical_shelves)),\n",
        "          'compression_ratio': float(shelf_compression_ratio),\n",
        "          'duplicates_eliminated': int(len(unique_shelves)-len(unique_canonical_shelves)),\n",
        "      }\n",
        "  }\n",
        "}\n",
        "with open(outputs_dir/\"canonicalization_metadata.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"‚úÖ Saved mappings + metadata in {outputs_dir}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Romance Research (venv)",
      "language": "python",
      "name": "romance-research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
