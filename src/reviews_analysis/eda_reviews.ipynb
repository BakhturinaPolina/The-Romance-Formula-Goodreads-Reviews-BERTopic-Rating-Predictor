{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Goodreads Reviews\n",
    "\n",
    "This notebook performs comprehensive EDA on English Goodreads reviews for 6,000 romance novels, analyzing:\n",
    "- Review count distributions (overall and by quality tier)\n",
    "- Review length distributions (characters and tokens)\n",
    "- Ratings distributions\n",
    "- Lexical patterns by quality tier\n",
    "\n",
    "**Data Sources:**\n",
    "- Books: `data/processed/romance_subdataset_6000.csv`\n",
    "- Reviews: `data/processed/romance_reviews_english_subdataset_6000.csv`\n",
    "- Coverage: `data/interim/review_coverage_by_book.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:30:02.768755Z",
     "iopub.status.busy": "2025-11-13T16:30:02.768244Z",
     "iopub.status.idle": "2025-11-13T16:30:05.371598Z",
     "shell.execute_reply": "2025-11-13T16:30:05.365840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Output directory: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "# Add project root to path\n",
    "# Use absolute path to project root (works in both Jupyter and script execution)\n",
    "project_root = Path('/home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# Change to project root directory for relative paths to work\n",
    "import os\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Import our modules\n",
    "from reviews_analysis.data_loading import load_joined_reviews\n",
    "from reviews_analysis.checks_coverage import generate_coverage_table\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Antique color palette (from user preferences)\n",
    "ANTIQUE_COLORS = [\n",
    "    '#855C75FF', '#D9AF6BFF', '#AF6458FF', '#736F4CFF', \n",
    "    '#526A83FF', '#625377FF', '#68855CFF', '#9C9C5EFF', \n",
    "    '#A06177FF', '#8C785DFF', '#467378FF', '#7C7C7CFF'\n",
    "]\n",
    "\n",
    "# Create output directory\n",
    "output_dir = project_root / \"reports\" / \"reviews_eda\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Output directory: {output_dir}\")\n",
    "logger.info(\"Setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:30:05.528181Z",
     "iopub.status.busy": "2025-11-13T16:30:05.527094Z",
     "iopub.status.idle": "2025-11-13T16:30:38.194873Z",
     "shell.execute_reply": "2025-11-13T16:30:38.191547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading joined reviews and books data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Loading books dataset from: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/data/processed/romance_subdataset_6000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Loaded 6,000 books\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Pop tier distribution:\n",
      "pop_tier\n",
      "thrash    2000\n",
      "mid       2000\n",
      "top       2000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Loading reviews dataset from: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/data/processed/romance_reviews_english_subdataset_6000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Loaded 969,675 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Unique books in reviews: 17,659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Joining books and reviews datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:  Books: 6,000 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:  Reviews: 969,675 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Loading book_id -> work_id mapping from: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/data/processed/romance_books_main_final.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Filtered to 6,000 works from subdataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Created mapping: 18,035 book_ids -> 6,000 work_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Mapping book_id to work_id in reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:  Mapped: 969,675 reviews (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Joined dataset: 969,675 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reviews_analysis.data_loading:Books with reviews: 5,998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded 969,675 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Unique books: 5,998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Columns: ['review_id', 'review_text', 'rating', 'book_id', 'work_id', 'title', 'author_id', 'author_name', 'publication_year', 'num_pages_median', 'genres_str', 'series_id', 'series_title', 'ratings_count_sum', 'text_reviews_count_sum', 'average_rating_weighted_mean', 'pop_tier']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (969675, 17)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>num_pages_median</th>\n",
       "      <th>genres_str</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_title</th>\n",
       "      <th>ratings_count_sum</th>\n",
       "      <th>text_reviews_count_sum</th>\n",
       "      <th>average_rating_weighted_mean</th>\n",
       "      <th>pop_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f73a70f64564d4a8f4cfb2d2e9d5836f</td>\n",
       "      <td>Enjoyable read! I liked that Connie is not a t...</td>\n",
       "      <td>4</td>\n",
       "      <td>7840190</td>\n",
       "      <td>21509416</td>\n",
       "      <td>Bait</td>\n",
       "      <td>3132972</td>\n",
       "      <td>Annie Nicholas</td>\n",
       "      <td>2010</td>\n",
       "      <td>269.0</td>\n",
       "      <td>fantasy, fiction, mystery, paranormal, romance</td>\n",
       "      <td>406250.0</td>\n",
       "      <td>Angler</td>\n",
       "      <td>2504</td>\n",
       "      <td>230</td>\n",
       "      <td>3.70</td>\n",
       "      <td>thrash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768e4a82b89e36055706857e9268b8e9</td>\n",
       "      <td>I really enjoyed this book! Chick lit with bra...</td>\n",
       "      <td>5</td>\n",
       "      <td>2718668</td>\n",
       "      <td>2744265</td>\n",
       "      <td>A Family Affair</td>\n",
       "      <td>363909</td>\n",
       "      <td>Mary Campisi</td>\n",
       "      <td>2006</td>\n",
       "      <td>351.0</td>\n",
       "      <td>fiction, mystery, romance</td>\n",
       "      <td>542852.0</td>\n",
       "      <td>Truth in Lies</td>\n",
       "      <td>11490</td>\n",
       "      <td>928</td>\n",
       "      <td>3.63</td>\n",
       "      <td>thrash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77ecec100fdb475116e9cd75a77dc00d</td>\n",
       "      <td>Eh...a lil harlequin romance anyone?</td>\n",
       "      <td>2</td>\n",
       "      <td>2761356</td>\n",
       "      <td>2787065</td>\n",
       "      <td>The Sweet Gum Tree</td>\n",
       "      <td>1077176</td>\n",
       "      <td>Katherine Allred</td>\n",
       "      <td>2005</td>\n",
       "      <td>304.0</td>\n",
       "      <td>fiction, romance, young adult</td>\n",
       "      <td>stand_alone</td>\n",
       "      <td>stand_alone</td>\n",
       "      <td>24509</td>\n",
       "      <td>2877</td>\n",
       "      <td>4.30</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63ff74279e46b247cb1754313b160006</td>\n",
       "      <td>I finished reading this days ago and cant get ...</td>\n",
       "      <td>4</td>\n",
       "      <td>15507958</td>\n",
       "      <td>17763198</td>\n",
       "      <td>Me Before You</td>\n",
       "      <td>281810</td>\n",
       "      <td>Jojo Moyes</td>\n",
       "      <td>2012</td>\n",
       "      <td>385.0</td>\n",
       "      <td>fiction, romance</td>\n",
       "      <td>747511.0</td>\n",
       "      <td>Me Before You</td>\n",
       "      <td>737888</td>\n",
       "      <td>67781</td>\n",
       "      <td>4.27</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d27adfd2eec3cddb66954e87cf9ab197</td>\n",
       "      <td>** spoiler alert ** \\n So many people have sai...</td>\n",
       "      <td>5</td>\n",
       "      <td>17183734</td>\n",
       "      <td>21880254</td>\n",
       "      <td>The Edge of Never</td>\n",
       "      <td>5437976</td>\n",
       "      <td>J.A. Redmerski</td>\n",
       "      <td>2012</td>\n",
       "      <td>439.0</td>\n",
       "      <td>fiction, romance, young adult</td>\n",
       "      <td>471797.0</td>\n",
       "      <td>The Edge of Never</td>\n",
       "      <td>126458</td>\n",
       "      <td>10295</td>\n",
       "      <td>4.26</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  f73a70f64564d4a8f4cfb2d2e9d5836f   \n",
       "1  768e4a82b89e36055706857e9268b8e9   \n",
       "2  77ecec100fdb475116e9cd75a77dc00d   \n",
       "3  63ff74279e46b247cb1754313b160006   \n",
       "4  d27adfd2eec3cddb66954e87cf9ab197   \n",
       "\n",
       "                                         review_text  rating   book_id  \\\n",
       "0  Enjoyable read! I liked that Connie is not a t...       4   7840190   \n",
       "1  I really enjoyed this book! Chick lit with bra...       5   2718668   \n",
       "2               Eh...a lil harlequin romance anyone?       2   2761356   \n",
       "3  I finished reading this days ago and cant get ...       4  15507958   \n",
       "4  ** spoiler alert ** \\n So many people have sai...       5  17183734   \n",
       "\n",
       "    work_id               title  author_id       author_name  \\\n",
       "0  21509416                Bait    3132972    Annie Nicholas   \n",
       "1   2744265     A Family Affair     363909      Mary Campisi   \n",
       "2   2787065  The Sweet Gum Tree    1077176  Katherine Allred   \n",
       "3  17763198       Me Before You     281810        Jojo Moyes   \n",
       "4  21880254   The Edge of Never    5437976    J.A. Redmerski   \n",
       "\n",
       "   publication_year  num_pages_median  \\\n",
       "0              2010             269.0   \n",
       "1              2006             351.0   \n",
       "2              2005             304.0   \n",
       "3              2012             385.0   \n",
       "4              2012             439.0   \n",
       "\n",
       "                                       genres_str    series_id  \\\n",
       "0  fantasy, fiction, mystery, paranormal, romance     406250.0   \n",
       "1                       fiction, mystery, romance     542852.0   \n",
       "2                   fiction, romance, young adult  stand_alone   \n",
       "3                                fiction, romance     747511.0   \n",
       "4                   fiction, romance, young adult     471797.0   \n",
       "\n",
       "        series_title  ratings_count_sum  text_reviews_count_sum  \\\n",
       "0             Angler               2504                     230   \n",
       "1      Truth in Lies              11490                     928   \n",
       "2        stand_alone              24509                    2877   \n",
       "3      Me Before You             737888                   67781   \n",
       "4  The Edge of Never             126458                   10295   \n",
       "\n",
       "   average_rating_weighted_mean pop_tier  \n",
       "0                          3.70   thrash  \n",
       "1                          3.63   thrash  \n",
       "2                          4.30      top  \n",
       "3                          4.27      top  \n",
       "4                          4.26      top  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "logger.info(\"Loading joined reviews and books data...\")\n",
    "joined_df = load_joined_reviews(how=\"inner\")  # Only books with reviews\n",
    "\n",
    "logger.info(f\"Loaded {len(joined_df):,} reviews\")\n",
    "logger.info(f\"Unique books: {joined_df['work_id'].nunique():,}\")\n",
    "logger.info(f\"Columns: {list(joined_df.columns)}\")\n",
    "\n",
    "# Check data types and basic info\n",
    "print(\"\\nData shape:\", joined_df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:30:38.205433Z",
     "iopub.status.busy": "2025-11-13T16:30:38.204401Z",
     "iopub.status.idle": "2025-11-13T16:31:48.787834Z",
     "shell.execute_reply": "2025-11-13T16:31:48.784846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Computing review lengths...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length (characters):\n",
      "  Mean: 747.8\n",
      "  Median: 348.0\n",
      "  Min: 10\n",
      "  Max: 20,024\n",
      "\n",
      "Review length (tokens):\n",
      "  Mean: 137.7\n",
      "  Median: 65.0\n",
      "  Min: 1\n",
      "  Max: 3,789\n"
     ]
    }
   ],
   "source": [
    "# Compute review lengths (characters and tokens)\n",
    "logger.info(\"Computing review lengths...\")\n",
    "\n",
    "# Character count\n",
    "joined_df['review_length_chars'] = joined_df['review_text'].str.len()\n",
    "\n",
    "# Token count (simple word count for now)\n",
    "joined_df['review_length_tokens'] = joined_df['review_text'].str.split().str.len()\n",
    "\n",
    "# Log basic statistics\n",
    "print(f\"Review length (characters):\")\n",
    "print(f\"  Mean: {joined_df['review_length_chars'].mean():.1f}\")\n",
    "print(f\"  Median: {joined_df['review_length_chars'].median():.1f}\")\n",
    "print(f\"  Min: {joined_df['review_length_chars'].min()}\")\n",
    "print(f\"  Max: {joined_df['review_length_chars'].max():,}\")\n",
    "\n",
    "print(f\"\\nReview length (tokens):\")\n",
    "print(f\"  Mean: {joined_df['review_length_tokens'].mean():.1f}\")\n",
    "print(f\"  Median: {joined_df['review_length_tokens'].median():.1f}\")\n",
    "print(f\"  Min: {joined_df['review_length_tokens'].min()}\")\n",
    "print(f\"  Max: {joined_df['review_length_tokens'].max():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:31:48.793661Z",
     "iopub.status.busy": "2025-11-13T16:31:48.793071Z",
     "iopub.status.idle": "2025-11-13T16:32:03.422813Z",
     "shell.execute_reply": "2025-11-13T16:32:03.420193Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating review count distribution plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/review_count_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# 1. Distribution of reviews per book (overall and by pop_tier)\n",
    "logger.info(\"Creating review count distribution plots...\")\n",
    "\n",
    "# Get review counts per book\n",
    "review_counts = joined_df.groupby(['work_id', 'pop_tier']).size().reset_index(name='n_reviews')\n",
    "review_counts_by_tier = review_counts.groupby('pop_tier')['n_reviews'].apply(list).to_dict()\n",
    "\n",
    "# Create figure with 2x2 layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Review Count Distribution by Quality Tier', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall distribution\n",
    "ax = axes[0, 0]\n",
    "ax.hist(review_counts['n_reviews'], bins=50, color=ANTIQUE_COLORS[0], alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Number of Reviews per Book')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Overall Distribution')\n",
    "ax.set_xlim(0, 1000)  # Focus on most books\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# By tier - histograms\n",
    "tier_order = ['thrash', 'mid', 'top']\n",
    "tier_labels = ['Trash', 'Middle', 'Top']\n",
    "tier_colors = [ANTIQUE_COLORS[0], ANTIQUE_COLORS[4], ANTIQUE_COLORS[8]]\n",
    "\n",
    "# Place tiers in remaining 3 subplots: [0,1], [1,0], [1,1]\n",
    "tier_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "for idx, (tier, label, color) in enumerate(zip(tier_order, tier_labels, tier_colors)):\n",
    "    row, col = tier_positions[idx]\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    if tier in review_counts_by_tier:\n",
    "        ax.hist(review_counts_by_tier[tier], bins=50, color=color, alpha=0.7, edgecolor='black')\n",
    "        ax.set_xlabel('Number of Reviews per Book')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'{label} Tier')\n",
    "        ax.set_xlim(0, 1000)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'review_count_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close to free memory\n",
    "logger.info(f\"Saved: {output_dir / 'review_count_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:32:03.433065Z",
     "iopub.status.busy": "2025-11-13T16:32:03.432206Z",
     "iopub.status.idle": "2025-11-13T16:32:11.210316Z",
     "shell.execute_reply": "2025-11-13T16:32:11.207177Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating review length distribution plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/review_length_chars_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# 2. Review length distributions (characters and tokens) by pop_tier\n",
    "logger.info(\"Creating review length distribution plots...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Review Length Distribution by Quality Tier', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall character length\n",
    "ax = axes[0, 0]\n",
    "ax.hist(joined_df['review_length_chars'], bins=100, color=ANTIQUE_COLORS[0], alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Review Length (characters)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Overall Character Length')\n",
    "ax.set_xlim(0, 5000)  # Focus on most reviews\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Character length by tier\n",
    "tier_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "for idx, (tier, label, color) in enumerate(zip(tier_order, tier_labels, tier_colors)):\n",
    "    row, col = tier_positions[idx]\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    tier_data = joined_df[joined_df['pop_tier'] == tier]['review_length_chars']\n",
    "    ax.hist(tier_data, bins=100, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Review Length (characters)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{label} Tier Character Length')\n",
    "    ax.set_xlim(0, 5000)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'review_length_chars_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close to free memory\n",
    "logger.info(f\"Saved: {output_dir / 'review_length_chars_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:32:11.221797Z",
     "iopub.status.busy": "2025-11-13T16:32:11.221199Z",
     "iopub.status.idle": "2025-11-13T16:32:18.859007Z",
     "shell.execute_reply": "2025-11-13T16:32:18.853328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/review_length_tokens_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Token length distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Review Token Count Distribution by Quality Tier', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall token length\n",
    "ax = axes[0, 0]\n",
    "ax.hist(joined_df['review_length_tokens'], bins=100, color=ANTIQUE_COLORS[0], alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Review Length (tokens)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Overall Token Count')\n",
    "ax.set_xlim(0, 1000)  # Focus on most reviews\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Token length by tier\n",
    "tier_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "for idx, (tier, label, color) in enumerate(zip(tier_order, tier_labels, tier_colors)):\n",
    "    row, col = tier_positions[idx]\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    tier_data = joined_df[joined_df['pop_tier'] == tier]['review_length_tokens']\n",
    "    ax.hist(tier_data, bins=100, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Review Length (tokens)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{label} Tier Token Count')\n",
    "    ax.set_xlim(0, 1000)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'review_length_tokens_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close to free memory\n",
    "logger.info(f\"Saved: {output_dir / 'review_length_tokens_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:32:18.867854Z",
     "iopub.status.busy": "2025-11-13T16:32:18.867243Z",
     "iopub.status.idle": "2025-11-13T16:32:25.754696Z",
     "shell.execute_reply": "2025-11-13T16:32:25.748990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Analyzing ratings distribution...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings available: True\n",
      "Valid ratings: 969,675 (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/ratings_distribution.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rating statistics by tier:\n",
      "\n",
      "Trash:\n",
      "  Mean: 3.35\n",
      "  Median: 4.00\n",
      "  Count: 121,343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Middle:\n",
      "  Mean: 3.89\n",
      "  Median: 4.00\n",
      "  Count: 480,126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top:\n",
      "  Mean: 4.27\n",
      "  Median: 5.00\n",
      "  Count: 368,206\n"
     ]
    }
   ],
   "source": [
    "# 3. Ratings distribution (if available)\n",
    "logger.info(\"Analyzing ratings distribution...\")\n",
    "\n",
    "# Check if ratings are available and valid\n",
    "ratings_available = 'rating' in joined_df.columns\n",
    "if ratings_available:\n",
    "    # Convert rating to numeric, handling empty strings\n",
    "    joined_df['rating_numeric'] = pd.to_numeric(joined_df['rating'], errors='coerce')\n",
    "    ratings_valid = joined_df['rating_numeric'].notna().sum()\n",
    "    \n",
    "    print(f\"Ratings available: {ratings_available}\")\n",
    "    print(f\"Valid ratings: {ratings_valid:,} ({ratings_valid/len(joined_df)*100:.1f}%)\")\n",
    "    \n",
    "    if ratings_valid > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('Rating Distribution by Quality Tier', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Overall ratings\n",
    "        ax = axes[0, 0]\n",
    "        valid_ratings = joined_df['rating_numeric'].dropna()\n",
    "        ax.hist(valid_ratings, bins=5, color=ANTIQUE_COLORS[0], alpha=0.7, edgecolor='black', align='left')\n",
    "        ax.set_xlabel('Rating (stars)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Overall Rating Distribution')\n",
    "        ax.set_xticks([1, 2, 3, 4, 5])\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Ratings by tier\n",
    "        tier_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "        for idx, (tier, label, color) in enumerate(zip(tier_order, tier_labels, tier_colors)):\n",
    "            row, col = tier_positions[idx]\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            tier_ratings = joined_df[joined_df['pop_tier'] == tier]['rating_numeric'].dropna()\n",
    "            if len(tier_ratings) > 0:\n",
    "                ax.hist(tier_ratings, bins=5, color=color, alpha=0.7, edgecolor='black', align='left')\n",
    "                ax.set_xlabel('Rating (stars)')\n",
    "                ax.set_ylabel('Frequency')\n",
    "                ax.set_title(f'{label} Tier Ratings')\n",
    "                ax.set_xticks([1, 2, 3, 4, 5])\n",
    "                ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'ratings_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()  # Close to free memory\n",
    "        \n",
    "        logger.info(f\"Saved: {output_dir / 'ratings_distribution.png'}\")\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nRating statistics by tier:\")\n",
    "        for tier, label in zip(tier_order, tier_labels):\n",
    "            tier_ratings = joined_df[joined_df['pop_tier'] == tier]['rating_numeric'].dropna()\n",
    "            if len(tier_ratings) > 0:\n",
    "                print(f\"\\n{label}:\")\n",
    "                print(f\"  Mean: {tier_ratings.mean():.2f}\")\n",
    "                print(f\"  Median: {tier_ratings.median():.2f}\")\n",
    "                print(f\"  Count: {len(tier_ratings):,}\")\n",
    "else:\n",
    "    print(\"Ratings not available in dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:32:25.764017Z",
     "iopub.status.busy": "2025-11-13T16:32:25.763238Z",
     "iopub.status.idle": "2025-11-13T16:32:33.118424Z",
     "shell.execute_reply": "2025-11-13T16:32:33.114566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating comparison boxplots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147381/3085279190.py:24: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_for_box, labels=tier_labels, widths=0.6, patch_artist=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147381/3085279190.py:37: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_for_box, labels=tier_labels, widths=0.6, patch_artist=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/review_metrics_boxplots.png\n"
     ]
    }
   ],
   "source": [
    "# 4. Boxplots comparing distributions by tier\n",
    "logger.info(\"Creating comparison boxplots...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Review Metrics Comparison by Quality Tier', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Review counts per book\n",
    "ax = axes[0]\n",
    "review_counts_pivot = review_counts.pivot(columns='pop_tier', values='n_reviews')\n",
    "review_counts_pivot.boxplot(ax=ax, positions=[0, 1, 2], widths=0.6, \n",
    "                           patch_artist=True,\n",
    "                           boxprops=dict(facecolor=ANTIQUE_COLORS[0], alpha=0.7),\n",
    "                           medianprops=dict(color='black', linewidth=2))\n",
    "ax.set_xticklabels(tier_labels)\n",
    "ax.set_ylabel('Number of Reviews per Book')\n",
    "ax.set_title('Review Counts per Book')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 500)  # Focus on most books\n",
    "\n",
    "# Review length (characters)\n",
    "ax = axes[1]\n",
    "data_for_box = [joined_df[joined_df['pop_tier'] == tier]['review_length_chars'].dropna() \n",
    "                for tier in tier_order]\n",
    "bp = ax.boxplot(data_for_box, labels=tier_labels, widths=0.6, patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], tier_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "ax.set_ylabel('Review Length (characters)')\n",
    "ax.set_title('Review Character Length')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 3000)\n",
    "\n",
    "# Review length (tokens)\n",
    "ax = axes[2]\n",
    "data_for_box = [joined_df[joined_df['pop_tier'] == tier]['review_length_tokens'].dropna() \n",
    "                for tier in tier_order]\n",
    "bp = ax.boxplot(data_for_box, labels=tier_labels, widths=0.6, patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], tier_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "ax.set_ylabel('Review Length (tokens)')\n",
    "ax.set_title('Review Token Count')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 600)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'review_metrics_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close to free memory\n",
    "logger.info(f\"Saved: {output_dir / 'review_metrics_boxplots.png'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:32:33.132026Z",
     "iopub.status.busy": "2025-11-13T16:32:33.129833Z",
     "iopub.status.idle": "2025-11-13T16:35:04.718854Z",
     "shell.execute_reply": "2025-11-13T16:35:04.716383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Performing lexical analysis...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words by quality tier:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trash Tier:\n",
      "  not: 98,154\n",
      "  just: 74,181\n",
      "  like: 73,910\n",
      "  one: 68,864\n",
      "  all: 66,686\n",
      "  about: 65,541\n",
      "  really: 64,768\n",
      "  love: 64,074\n",
      "  what: 61,848\n",
      "  more: 59,375\n",
      "  out: 52,389\n",
      "  when: 51,968\n",
      "  there: 51,667\n",
      "  who: 44,777\n",
      "  how: 41,217\n",
      "  because: 39,039\n",
      "  very: 38,205\n",
      "  get: 37,270\n",
      "  good: 37,047\n",
      "  some: 36,628\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle Tier:\n",
      "  not: 344,097\n",
      "  love: 312,676\n",
      "  just: 300,194\n",
      "  one: 300,144\n",
      "  like: 280,678\n",
      "  all: 267,650\n",
      "  really: 247,735\n",
      "  about: 238,200\n",
      "  more: 234,854\n",
      "  what: 227,652\n",
      "  when: 199,323\n",
      "  out: 193,218\n",
      "  there: 186,509\n",
      "  loved: 184,124\n",
      "  how: 172,400\n",
      "  who: 161,971\n",
      "  because: 156,182\n",
      "  much: 150,936\n",
      "  get: 146,580\n",
      "  series: 145,332\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Tier:\n",
      "  love: 300,890\n",
      "  not: 261,739\n",
      "  one: 253,467\n",
      "  just: 239,834\n",
      "  all: 235,587\n",
      "  like: 198,433\n",
      "  more: 195,689\n",
      "  series: 191,338\n",
      "  what: 189,751\n",
      "  about: 183,809\n",
      "  really: 168,281\n",
      "  loved: 166,615\n",
      "  when: 160,010\n",
      "  out: 154,294\n",
      "  how: 150,407\n",
      "  there: 148,294\n",
      "  much: 129,021\n",
      "  get: 127,532\n",
      "  because: 122,695\n",
      "  who: 117,831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Basic lexical analysis: frequent words by tier\n",
    "logger.info(\"Performing lexical analysis...\")\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning for word frequency analysis.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Convert to lowercase and remove punctuation\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "# Common stopwords (basic list)\n",
    "stopwords = {\n",
    "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "    'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those',\n",
    "    'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "    'my', 'your', 'his', 'her', 'its', 'our', 'their', 'book', 'books', 'read',\n",
    "    'reading', 'review', 'reviews', 'story', 'character', 'characters', 'plot'\n",
    "}\n",
    "\n",
    "def get_top_words(text_series, n=20):\n",
    "    \"\"\"Get top N words from a series of texts.\"\"\"\n",
    "    all_words = []\n",
    "    for text in text_series:\n",
    "        cleaned = clean_text(text)\n",
    "        words = cleaned.split()\n",
    "        all_words.extend([w for w in words if w not in stopwords and len(w) > 2])\n",
    "    \n",
    "    word_counts = Counter(all_words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Get top words by tier\n",
    "print(\"Top 20 words by quality tier:\\n\")\n",
    "top_words_by_tier = {}\n",
    "for tier, label in zip(tier_order, tier_labels):\n",
    "    tier_reviews = joined_df[joined_df['pop_tier'] == tier]['review_text']\n",
    "    top_words = get_top_words(tier_reviews, n=20)\n",
    "    top_words_by_tier[tier] = top_words\n",
    "    \n",
    "    print(f\"{label} Tier:\")\n",
    "    for word, count in top_words:\n",
    "        print(f\"  {word}: {count:,}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:35:04.725980Z",
     "iopub.status.busy": "2025-11-13T16:35:04.724809Z",
     "iopub.status.idle": "2025-11-13T16:35:08.637197Z",
     "shell.execute_reply": "2025-11-13T16:35:08.634250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/top_words_by_tier.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize top words by tier\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Top 15 Words by Quality Tier', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (tier, label, color) in enumerate(zip(tier_order, tier_labels, tier_colors)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if tier in top_words_by_tier:\n",
    "        words, counts = zip(*top_words_by_tier[tier][:15])\n",
    "        words = list(words)[::-1]  # Reverse for horizontal bar\n",
    "        counts = list(counts)[::-1]\n",
    "        \n",
    "        ax.barh(range(len(words)), counts, color=color, alpha=0.7)\n",
    "        ax.set_yticks(range(len(words)))\n",
    "        ax.set_yticklabels(words)\n",
    "        ax.set_xlabel('Frequency')\n",
    "        ax.set_title(f'{label} Tier')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'top_words_by_tier.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close to free memory\n",
    "logger.info(f\"Saved: {output_dir / 'top_words_by_tier.png'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:35:08.644209Z",
     "iopub.status.busy": "2025-11-13T16:35:08.643097Z",
     "iopub.status.idle": "2025-11-13T16:35:10.359155Z",
     "shell.execute_reply": "2025-11-13T16:35:10.354088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating summary statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved summary statistics to: /home/polina/Documents/goodreads_romance_research_cursor/romance_novel_nlp_research/reports/reviews_eda/summary_statistics.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics by Quality Tier:\n",
      "  Tier  Total Reviews  Unique Books  Mean Reviews per Book  Median Reviews per Book  Mean Review Length (chars)  Median Review Length (chars)  Mean Review Length (tokens)  Median Review Length (tokens)  Mean Rating  Median Rating  Reviews with Ratings\n",
      " Trash         121343          1999              60.701851                     29.0                  757.478042                         375.0                   138.793824                           70.0     3.349546            4.0                121343\n",
      "Middle         480126          2000             240.063000                    134.0                  731.877563                         338.0                   134.635696                           63.0     3.885505            4.0                480126\n",
      "   Top         368206          1999             184.195098                     79.0                  765.396740                         352.0                   141.422492                           66.0     4.268317            5.0                368206\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics table\n",
    "logger.info(\"Generating summary statistics...\")\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "for tier, label in zip(tier_order, tier_labels):\n",
    "    tier_data = joined_df[joined_df['pop_tier'] == tier]\n",
    "    \n",
    "    stats = {\n",
    "        'Tier': label,\n",
    "        'Total Reviews': len(tier_data),\n",
    "        'Unique Books': tier_data['work_id'].nunique(),\n",
    "        'Mean Reviews per Book': tier_data.groupby('work_id').size().mean(),\n",
    "        'Median Reviews per Book': tier_data.groupby('work_id').size().median(),\n",
    "        'Mean Review Length (chars)': tier_data['review_length_chars'].mean(),\n",
    "        'Median Review Length (chars)': tier_data['review_length_chars'].median(),\n",
    "        'Mean Review Length (tokens)': tier_data['review_length_tokens'].mean(),\n",
    "        'Median Review Length (tokens)': tier_data['review_length_tokens'].median(),\n",
    "    }\n",
    "    \n",
    "    if 'rating_numeric' in tier_data.columns:\n",
    "        valid_ratings = tier_data['rating_numeric'].dropna()\n",
    "        if len(valid_ratings) > 0:\n",
    "            stats['Mean Rating'] = valid_ratings.mean()\n",
    "            stats['Median Rating'] = valid_ratings.median()\n",
    "            stats['Reviews with Ratings'] = len(valid_ratings)\n",
    "    \n",
    "    summary_stats.append(stats)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\nSummary Statistics by Quality Tier:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(output_dir / 'summary_statistics.csv', index=False)\n",
    "logger.info(f\"Saved summary statistics to: {output_dir / 'summary_statistics.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This EDA has analyzed:\n",
    "1. ✅ Review count distributions (overall and by tier)\n",
    "2. ✅ Review length distributions (characters and tokens)\n",
    "3. ✅ Ratings distributions (if available)\n",
    "4. ✅ Lexical patterns (top words by tier)\n",
    "5. ✅ Summary statistics\n",
    "\n",
    "**Key Findings:**\n",
    "- Coverage: 5,998/6,000 books (99.97%) have reviews\n",
    "- Total reviews: 969,675\n",
    "- Clear differences in review patterns across quality tiers\n",
    "- MID tier has highest average reviews per book\n",
    "- Review lengths vary by tier\n",
    "\n",
    "All figures saved to `reports/reviews_eda/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
